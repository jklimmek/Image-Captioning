seq_len: 40
vocab_size: 10_000
proj_dim: 768
intermidiate_dim: 512
embed_dim: 384
nhead: 6
hidden_layer_multiplier: 4
activation: gelu
num_layers: 6
dropout: 0.1
learning_rate: 0.003
betas: [0.9, 0.999]
weight_decay: 0.1
label_smoothing: 0.0
batch_size: 128
max_epochs: 5